{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f16a95",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T03:09:43.072Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library('tidyverse')\n",
    "library(\"stringr\")\n",
    "library('purrr')\n",
    "library('foreach')\n",
    "library('magrittr')\n",
    "library('ggplot2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce4d1b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T03:09:43.453Z"
    }
   },
   "outputs": [],
   "source": [
    "restrict_to_dist_from_2022 = FALSE\n",
    "restrict_to_geno = TRUE\n",
    "restrict_to_2022_hybrids = TRUE\n",
    "save_suffix = 'smallAnyDist'\n",
    "# CV = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef3a2b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T03:09:43.788Z"
    }
   },
   "outputs": [],
   "source": [
    "needed_matrices = c(\"GPC\",\n",
    "                    \"GA\",\n",
    "                    \"GD\",\n",
    "                    \"K.Soil\", \n",
    "                    \"K.Weather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379267fc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T03:09:44.189Z"
    }
   },
   "outputs": [],
   "source": [
    "g_path = './data/Maize_GxE_Competition_Data/Training_Data/5_Genotype_Data_All_Years.vcf/'\n",
    "AMat_file =           'Centered_IBS_Imputed_Imputed_5_Genotype_Data_All_Years_pres80maf05mbp100_KNNimp_with_Probability.txt'\n",
    "DMat_file = 'Dominance_Centered_IBS_Imputed_Imputed_5_Genotype_Data_All_Years_pres80maf05mbp100_KNNimp_with_Probability.txt'\n",
    "GPC_file =                      'PC_Imputed_Imputed_5_Genotype_Data_All_Years_pres80maf05mbp100_KNNimp_with_Probability.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44a22b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-23T03:09:44.742Z"
    }
   },
   "outputs": [],
   "source": [
    "# run for all CVs\n",
    "print(\"Beginning\")\n",
    "for(CV in 2014:2021){\n",
    "    print(CV)\n",
    "\n",
    "    data_loc <- './data/Processed/'\n",
    "\n",
    "    phno <- read.csv(paste0(data_loc, 'phno0.csv'))\n",
    "    phno <- phno[, c(\"Env\", \"Hybrid\", \"Year\", \"Yield_Mg_ha\")]\n",
    "    meta <- read.csv(paste0(data_loc, 'meta0.csv'))\n",
    "    soil <- read.csv(paste0(data_loc, 'soil0.csv'))\n",
    "    wthr <- read.csv(paste0(data_loc, 'wthrWide0.csv'), skip = 1)\n",
    "    # cgmv <- read.csv(paste0(data_loc, 'cgmv0.csv'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Restrict Observations\n",
    "\n",
    "    disallow_miss_env <- function(dfname = 'wthr'){\n",
    "        prep_path <- './data/Preparation/'\n",
    "        expect_csv <- paste0(dfname, '_Envs_miss.csv')\n",
    "\n",
    "        if(expect_csv %in% list.files(prep_path)){\n",
    "            return(read.csv(paste0(prep_path, expect_csv)))\n",
    "        }else{\n",
    "            print('File not found.')\n",
    "        }\n",
    "    }\n",
    "\n",
    "    disallow_imp <- function(dfname = 'wthr'){\n",
    "        files_found <- list.files(prep_path)\n",
    "        detections <- stringr::str_detect(files_found, paste0(dfname, '_Envs_imp_.+'))\n",
    "        files_matched <- files_found[detections]\n",
    "\n",
    "        out_list <- purrr::map(files_matched, function(file_matched){\n",
    "            out = read.csv(paste0(prep_path, file_matched))\n",
    "\n",
    "            colname = stringr::str_extract(file_matched, '_imp_.+')\n",
    "            colname = stringr::str_replace(unlist(colname), '_imp_', '')\n",
    "            colname = stringr::str_replace(unlist(colname), '\\\\.csv', '')\n",
    "\n",
    "            out[['Imputed']] = colname\n",
    "            return(out)        \n",
    "        })\n",
    "\n",
    "        out <- do.call(rbind, out_list)\n",
    "        return(out)\n",
    "    }\n",
    "    # NULL == disallow_imp(dfname = 'wthr')\n",
    "    # disallow_imp(dfname = 'meta')\n",
    "\n",
    "    ## Restrict based on missing wthr (not run)\n",
    "\n",
    "    # # restrict weather -- This makes sense for othe kinds of data but not wthr \n",
    "    # # since it's downloaded from POWER. Retained as an illustrative template\n",
    "\n",
    "    # restrict_to_nomiss_wthr = TRUE\n",
    "\n",
    "    # rm_Envs = disallow_miss_env(dfname = 'wthr')\n",
    "    # # confirm that no 2020 data is being removed\n",
    "    # list_Envs <- rm_Envs[['Absent_Envs']]\n",
    "    # list_2022_Envs <- \n",
    "    # stopifnot({function (x) x == 0} (length(list_2022_Envs)))\n",
    "\n",
    "    # # Remove disallowed envs\n",
    "    # phno <- phno[!(phno$Env %in% list_Envs), ]\n",
    "\n",
    "    dim(phno)\n",
    "\n",
    "    ## Restrict based on distance from 2022 sites\n",
    "\n",
    "    # restrict_to_dist_from_2022 = TRUE\n",
    "\n",
    "    # with distance of 1 this only has a minor affect 146,057 -> 132,925\n",
    "    min_dist = 1\n",
    "\n",
    "    if(restrict_to_dist_from_2022){\n",
    "        latlons <- meta[, c('Env', 'Year', 'Latitude_of_Field', 'Longitude_of_Field')] %>% distinct()\n",
    "        latlons2022 <- latlons[latlons$Year == 2022, ]\n",
    "        latlons['Pass'] = FALSE\n",
    "        latlons2022['Distance'] = FALSE\n",
    "\n",
    "        for(i in seq(1, nrow(latlons))){\n",
    "            lat <- latlons[i, 'Latitude_of_Field']\n",
    "            lon <- latlons[i, 'Longitude_of_Field']\n",
    "\n",
    "            latlons2022['Distance'] <- sqrt((latlons2022['Latitude_of_Field'] - lat)**2 + (latlons2022['Longitude_of_Field'] - lon)**2)\n",
    "\n",
    "            if(min(latlons2022['Distance']) <= min_dist){\n",
    "                  latlons[i, 'Pass'] <- TRUE\n",
    "            }\n",
    "        }\n",
    "\n",
    "        pass_Envs <-unique(latlons[latlons$Pass, 'Env'])\n",
    "        fail_Envs <-unique(latlons[!(latlons$Pass), 'Env'])\n",
    "\n",
    "        # Confirm this isn't removing any 2022 observations\n",
    "        stopifnot(!(TRUE %in% stringr::str_detect(fail_Envs, '2022')))\n",
    "\n",
    "        phno <- phno[phno$Env %in% pass_Envs, ]   \n",
    "    }\n",
    "\n",
    "    dim(phno)\n",
    "\n",
    "    ## Restrict based on 2022 Hybrids\n",
    "\n",
    "    # restrict_to_2022_hybrids = TRUE\n",
    "\n",
    "    # Remove observations for hybrids not in 2022\n",
    "    # Note: Doing this _DRAMATICALLY_ reduces the number of observations\n",
    "    # 146,057 -> 25,030\n",
    "\n",
    "    if (restrict_to_2022_hybrids){\n",
    "        hybrids_in_2022 <- unique(phno[phno$Year == 2022, 'Hybrid'] )\n",
    "        phno <- phno[phno$Hybrid %in% hybrids_in_2022, ] \n",
    "    }\n",
    "\n",
    "    dim(phno)\n",
    "\n",
    "    ## Restrict based on available G data\n",
    "\n",
    "    # restrict_to_geno = TRUE\n",
    "\n",
    "    if(restrict_to_geno){\n",
    "        # PCA info\n",
    "        geno <- read.table(paste0(\n",
    "            g_path,    \n",
    "            GPC_file\n",
    "        ), skip = 2, header = TRUE)\n",
    "\n",
    "        temp <- phno[!(phno$Hybrid %in% geno[['Taxa']]), 'Env']\n",
    "        # assert there are no values being removed from 2022\n",
    "        stopifnot(!(TRUE %in% stringr::str_detect(unique(temp), '2022')))\n",
    "\n",
    "        phno <- phno[(phno$Hybrid %in% geno[['Taxa']]), ] \n",
    "        rm(list = c('geno'))\n",
    "    } \n",
    "\n",
    "    dim(phno)\n",
    "\n",
    "    # Remake Systematically\n",
    "\n",
    "    if(TRUE){\n",
    "        ## W (ERM) matrix ------------------------------------------------------------\n",
    "        matrix_file <- paste0(\"y_matrix\", \"_\", as.character(CV), \"_\", save_suffix, '.rds')        \n",
    "        matrix_file_path = paste0(\"./data/Processed/\", matrix_file)\n",
    "        if (matrix_file %in% list.files(\"./data/Processed/\")){\n",
    "            doNothing <- TRUE\n",
    "        } else {\n",
    "            Y <- as.matrix(phno['Yield_Mg_ha'])\n",
    "            # Y \n",
    "            # mask based on CV\n",
    "            Y[phno$Year == CV] <- NA\n",
    "\n",
    "            ystd = sd(Y, na.rm = T)\n",
    "            ybar = mean(Y, na.rm = T)\n",
    "\n",
    "            Y = (Y - ybar)/ystd\n",
    "            saveRDS(Y , file = matrix_file_path)\n",
    "         }\n",
    "    }\n",
    "\n",
    "    if(\"GA\" %in% needed_matrices){\n",
    "        ## W (ERM) matrix ------------------------------------------------------------\n",
    "        matrix_file <- paste0(\"GA_matrix\", \"_\", as.character(CV), \"_\", save_suffix, '.rds')        \n",
    "        matrix_file_path = paste0(\"./data/Processed/\", matrix_file)\n",
    "        if (matrix_file %in% list.files(\"./data/Processed/\")){\n",
    "            doNothing <- TRUE\n",
    "        } else {\n",
    "            gc()\n",
    "            geno <- read.table(paste0(\n",
    "                g_path,    \n",
    "                AMat_file\n",
    "            ), skip = 3, header = FALSE)\n",
    "\n",
    "            # make a nxn matrix to hold the A matrix\n",
    "            geno_hybrid_index = geno[['V1']]\n",
    "\n",
    "            Gdat = as.matrix(geno[, 2:ncol(geno)])\n",
    "\n",
    "            rownames(Gdat) = geno_hybrid_index\n",
    "            colnames(Gdat) = geno_hybrid_index\n",
    "\n",
    "            AMat <- Gdat[phno$Hybrid, phno$Hybrid]\n",
    "            saveRDS(AMat , file = matrix_file_path)\n",
    "            rm(list = c('Gdat', 'geno'))\n",
    "            gc()    \n",
    "         }\n",
    "    }\n",
    "\n",
    "\n",
    "    if(\"GD\" %in% needed_matrices){\n",
    "        ## W (ERM) matrix ------------------------------------------------------------\n",
    "        matrix_file <- paste0(\"GD_matrix\", \"_\", as.character(CV), \"_\", save_suffix, '.rds')        \n",
    "        matrix_file_path = paste0(\"./data/Processed/\", matrix_file)\n",
    "        if (matrix_file %in% list.files(\"./data/Processed/\")){\n",
    "            doNothing <- TRUE\n",
    "        } else {\n",
    "            gc()\n",
    "            geno <- read.table(paste0(\n",
    "                g_path,    \n",
    "                DMat_file\n",
    "            ), skip = 3, header = FALSE)\n",
    "\n",
    "            # make a nxn matrix to hold the A matrix\n",
    "            geno_hybrid_index = geno[['V1']]\n",
    "\n",
    "            Gdat = as.matrix(geno[, 2:ncol(geno)])\n",
    "\n",
    "            rownames(Gdat) = geno_hybrid_index\n",
    "            colnames(Gdat) = geno_hybrid_index\n",
    "\n",
    "            DMat <- Gdat[phno$Hybrid, phno$Hybrid]\n",
    "            saveRDS(Gdat , file = matrix_file_path)\n",
    "            rm(list = c('Gdat', 'geno'))\n",
    "            gc()    \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    if(\"K.Soil\" %in% needed_matrices){\n",
    "        ## W (ERM) matrix ------------------------------------------------------------\n",
    "        matrix_file <- paste0(\"Ksoil_matrix\", \"_\", as.character(CV), \"_\", save_suffix, '.rds')        \n",
    "        matrix_file_path = paste0(\"./data/Processed/\", matrix_file)\n",
    "        if (matrix_file %in% list.files(\"./data/Processed/\")){\n",
    "            doNothing <- TRUE\n",
    "        } else {\n",
    "            soil_Envs <- soil$Env\n",
    "\n",
    "            soil_cols <- names(soil)[!(names(soil) %in% c('X', 'Env', 'Year'))]\n",
    "\n",
    "            scalings = do.call(rbind, purrr::map(soil_cols, function(col){\n",
    "                data.frame(col = c(col),\n",
    "                           mean = mean(soil[soil$Year != CV, col], na.rm=TRUE),\n",
    "                           std = sd(soil[soil$Year != CV, col], na.rm=TRUE))    \n",
    "            }) )\n",
    "            # TODO allow for saving of this df\n",
    "            # scalings\n",
    "            for(col in scalings$col){\n",
    "                soil[col] <- ((soil[col]-scalings[scalings$col == col, 'mean'])/scalings[scalings$col == col, 'std'])\n",
    "            }\n",
    "\n",
    "            Sdat <- as.matrix(soil[, soil_cols])\n",
    "            rownames(Sdat) <- soil_Envs\n",
    "\n",
    "            K.soil <- tcrossprod(Sdat)\n",
    "            K.soil <- K.soil/mean(diag(K.soil))\n",
    "            K.soil <- K.soil[phno$Env, phno$Env]\n",
    "\n",
    "            saveRDS(K.soil , file = matrix_file_path)\n",
    "            rm(list = c('Sdat'))\n",
    "            gc()  \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    if(\"K.Weather\" %in% needed_matrices){\n",
    "        ## W (ERM) matrix ------------------------------------------------------------\n",
    "        matrix_file <- paste0(\"Kweather_matrix\", \"_\", as.character(CV), \"_\", save_suffix, '.rds')        \n",
    "        matrix_file_path = paste0(\"./data/Processed/\", matrix_file)\n",
    "        if (matrix_file %in% list.files(\"./data/Processed/\")){\n",
    "            doNothing <- TRUE\n",
    "        } else {\n",
    "            # wthr_Envs <- wthr$X # because wthr wide has two levels of indexing when I skip the \n",
    "            # top level Env gets cut. \n",
    "            wthr_Envs_Planted <- paste(wthr$X, wthr$X.1, sep = '__')\n",
    "\n",
    "            # wthr_Envs\n",
    "            weather_ECs <- c(\n",
    "                'QV2M', 'T2MDEW', 'PS', 'RH2M', 'WS2M', 'GWETTOP', 'ALLSKY_SFC_SW_DWN', \n",
    "                'ALLSKY_SFC_PAR_TOT', 'T2M_MAX', 'T2M_MIN', 'T2MWET', 'GWETROOT', 'T2M', \n",
    "                'GWETPROF', 'ALLSKY_SFC_SW_DNI', 'PRECTOTCORR')\n",
    "\n",
    "            # keep only ecs (have format EC_Day# )\n",
    "            Wdat <- wthr[, names(wthr)[!(names(wthr) %in% c('variable', 'X'))]]\n",
    "\n",
    "\n",
    "\n",
    "            fix_col_day_numbers <- function(colname = 'ALLSKY_SFC_PAR_TOT_Day1'){\n",
    "                if(stringr::str_detect(colname, 'Day\\\\d+$')){\n",
    "                    daynum <- stringr::str_extract(colname, '\\\\d+$')\n",
    "                    if (as.numeric(daynum) >= 100){\n",
    "                        daynum <- daynum\n",
    "                    } else if (as.numeric(daynum) >= 10){\n",
    "                        daynum <- paste0('0', daynum)\n",
    "                    } else if (as.numeric(daynum) >= 1){\n",
    "                        daynum <- paste0('00', daynum)\n",
    "                    }\n",
    "                    return(stringr::str_replace(colname, '\\\\d+$', daynum))\n",
    "                } else {\n",
    "                    return(colname)\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # make sure the ECs are in a reasonable order\n",
    "            newNames <- unlist(map(names(Wdat), function(e){fix_col_day_numbers(colname = e)}))\n",
    "            names(Wdat) <- newNames\n",
    "            Wdat <- Wdat[, sort(newNames)]\n",
    "\n",
    "            Wdat <- as.matrix(Wdat)\n",
    "\n",
    "            rownames(Wdat) <- wthr_Envs_Planted\n",
    "\n",
    "            # Wdat#[, weather_ECs]\n",
    "\n",
    "\n",
    "\n",
    "            # env.weather is a list of 8 objects\n",
    "            # each object contains a matrix of 145 measurements x nObs\n",
    "            # these values are drawn from the input df\n",
    "            env.weather <- setNames(\n",
    "              foreach(weather_EC=weather_ECs) %do% {\n",
    "\n",
    "                # get the cols for each day's reading in form \n",
    "                # \"max_temp1\", \"max_temp2\" ... max_temp145\"\n",
    "                indx_of_weather_daily_vals = grep(paste0(\"^\", weather_EC, \"_\"), colnames(Wdat)) # <- Note: this underscore is critical to prevent \"P\" from not matching with photoperiod and PAR too. \n",
    "\n",
    "                # this is in nObs x Daily value (145)\n",
    "                E <- as.matrix(\n",
    "                  Wdat[, indx_of_weather_daily_vals]) %>% \n",
    "                  t # now it's Daily value x nObs\n",
    "\n",
    "                # New as of 2022 12 22 This forces the dates to be in the right order.\n",
    "                # i.e. so foo1 foo10, foo100... is replaced by foo1, foo2, foo3 ...\n",
    "                E <- E[sort(rownames(E)),]\n",
    "              }, \n",
    "              weather_ECs) # setNames() makes the matrices in this list accessible by name\n",
    "\n",
    "            make_ERM <- function(E_list, w, summary_functions = NULL) {\n",
    "              # create a list of nObsxnObs matrices and `.combine` them by adding the matrices together\n",
    "              # this results in a single nObsxnObs matrix aggregating all the enviromental covariates.\n",
    "\n",
    "              foreach(E = E_list, .combine = \"+\") %do% {\n",
    "                # Time bins\n",
    "                windows <- cut_interval(1:nrow(E), length = w) # this function is from ggplot2\n",
    "                # each 3 day period gets a new group:\n",
    "                # [1] [0,3] [0,3] [0,3]     (3,6] (3,6] (3,6]     (6,9] ...  \n",
    "                # [145] (144,147]\n",
    "                # Why this isn't done with seq is beyond me. Possibly because it returns cuts?\n",
    "\n",
    "                if (length(unique(windows)) == 1) {\n",
    "                  Z <- matrix(1, nrow = nrow(E), ncol = 1)\n",
    "                  # if the window length is one return a single column of ones\n",
    "\n",
    "                } else {\n",
    "                  Z <- model.matrix( ~ windows)\n",
    "                  # for window size three this becomes\n",
    "\n",
    "                  #   intercept win2 win3 ...\n",
    "                  # 1         1    0    0      # The first group is the intercept\n",
    "                  # 2         1    0    0\n",
    "                  # 3         1    0    0\n",
    "                  # 4         1    1    0      # One hot encoded groups\n",
    "                  # 5         1    1    0\n",
    "                  # 6         1    1    0\n",
    "                  # 7         1    0    1\n",
    "                  # 8         1    0    1\n",
    "                  # 9         1    0    1\n",
    "                  # ...\n",
    "                }\n",
    "\n",
    "                # # Average by time bin\n",
    "                # EC <- crossprod(Z,    # 145x49   window design matrix\n",
    "                #                 E     # 145xnObs data matrix\n",
    "                # ) %>% # 49xnObs \n",
    "                #   t %>%          # flip nObsx49\n",
    "                #   scale %>%      # center and scale each column\n",
    "                #   t %>%          # flip 49xnObs\n",
    "                #   na.omit\n",
    "\n",
    "                # Updated processing: The adapted code did not account for using \n",
    "                # management data where there might be no variability across groups (all\n",
    "                # groups recieve no fertilizer on a given day). This adapted version \n",
    "                # selectively scales entries to avoid these days becoming NA and being \n",
    "                # removed.\n",
    "\n",
    "                # Average by time bin\n",
    "                EC <- crossprod(Z,    # 145x49   window design matrix\n",
    "                                E     # 145xnObs data matrix\n",
    "                ) %>% # 49xnObs\n",
    "                  t #%>%          # flip nObsx49\n",
    "                # scale %>%      # center and scale each column\n",
    "                # replaced because this is introducing nas into 0s for `N`, `P` where columns are all 0 (i.e. when no fertilizer was applied)\n",
    "                # scale each column one at a time if and only if the sd != 0\n",
    "                # This prevents values from becoming NA and thus keeps the dimensions to the expected size\n",
    "                for(i in seq(1, ncol(EC))){\n",
    "                  if(sd(EC[,i]) != 0){\n",
    "                    EC[,i] = scale(EC[,i])\n",
    "                  } else {\n",
    "                    EC[,i] = scale(EC[,i], scale = FALSE)\n",
    "                  }\n",
    "                }\n",
    "                # and return to processing as normal\n",
    "                EC <- EC %>%\n",
    "                  t %>%          # flip 49xnObs\n",
    "                  na.omit\n",
    "\n",
    "\n",
    "                # Summary by time bin\n",
    "                # This functionality is not used\n",
    "                if (!is.null(summary_functions)) {\n",
    "                  EC_summary <- foreach(summary_function = summary_functions) %do% {\n",
    "                    summary_by_window <-\n",
    "                      by(E, windows, function(x)\n",
    "                        apply(x, 2, summary_function))\n",
    "\n",
    "                    do.call(rbind, summary_by_window) %>% t %>% scale %>% t %>% na.omit\n",
    "                  } %>% as.list\n",
    "\n",
    "                  EC <- do.call(rbind, append(list(EC), EC_summary))\n",
    "                }\n",
    "                # Environmental relationship matrix\n",
    "                return(crossprod(EC)) # Return a nObsxnObs matrix\n",
    "              }\n",
    "            }\n",
    "\n",
    "            K.weather <- make_ERM(env.weather, w = 3) # Make an environmental relationship matrix of nObs x nObs\n",
    "            K.weather <- K.weather/mean(diag(K.weather))\n",
    "            gc()\n",
    "\n",
    "    #         dim(K.weather)\n",
    "\n",
    "            # Expand matrix to be the target size\n",
    "\n",
    "            # there are some locations that have multiple planting dates for the same hybrids\n",
    "            # e.g. ARH1_2016\tA3G-3-3-1-313/DK3IIH6\n",
    "            # Due to time constraints I'm going to take the earliest for each Env x Hybrid and \n",
    "            # accept that there will be some error introduced.\n",
    "            # meta[, c(\"Env\", \"Hybrid\", 'Date_Planted')]  %>% distinct() %>% group_by(Env, Hybrid) %>% tally()\n",
    "\n",
    "            meta_min <- meta[, c(\"Env\", \"Hybrid\", 'Date_Planted')]  %>% \n",
    "                distinct() %>% \n",
    "                group_by(Env, Hybrid) %>% \n",
    "                mutate(Date_Planted = min(Date_Planted, na.rm = TRUE)) %>% \n",
    "                mutate(Date_Planted = round(Date_Planted)) %>% \n",
    "                mutate(Date_Planted = as.character(Date_Planted)) %>% \n",
    "\n",
    "                distinct() %>% \n",
    "                ungroup()\n",
    "\n",
    "\n",
    "            wthr_matches <- dplyr::left_join(\n",
    "                phno, \n",
    "                meta_min, by = c('Env', 'Hybrid')) %>% \n",
    "                mutate(Match_String = paste(Env, Date_Planted, sep = '__'))\n",
    "\n",
    "\n",
    "            # There are a bunch of off by one errors in the names. This is the quick and\n",
    "            # rough fix\n",
    "            convert_Env_Planting <- data.frame(\n",
    "                inPhno =      c(\"DEH1_2022__120\", \"GAH2_2022__116\", \"IAH1_2022__132\", \"IAH3_2022__134\", \"ILH1_2022__132\", \"INH1_2022__133\", \"MIH1_2022__138\", \"MOH2_2022__131\", \"NCH1_2022__112\", \"NEH2_2022__135\", \"NEH3_2022__135\", \"NYH2_2022__144\", \"NYH3_2022__144\", \"TXH1_2022__107\", \"TXH2_2022__107\", \"TXH3_2022__107\", \"WIH2_2022__137\", \"WIH3_2022__137\"),\n",
    "                inK.weather = c('DEH1_2022__121', 'GAH2_2022__117', 'IAH1_2022__133', 'IAH3_2022__135', 'ILH1_2022__133', 'INH1_2022__134', 'MNH1_2022__137', 'MOH2_2022__132', 'NCH1_2022__113', 'NEH2_2022__136', 'NEH3_2022__136', 'NYH2_2022__145', 'NYH3_2022__145', 'TXH1_2022__108', 'TXH2_2022__108', 'TXH3_2022__108', 'WIH2_2022__138', 'WIH3_2022__138')    \n",
    "            )\n",
    "\n",
    "            for(i in 1:nrow(convert_Env_Planting)){\n",
    "                mask <- wthr_matches$Match_String == convert_Env_Planting[i, 'inK.weather']\n",
    "                wthr_matches[mask, 'Match_String'] <- convert_Env_Planting[i, 'inPhno']\n",
    "            }\n",
    "            # assert all are in wthr_matches / K.weather\n",
    "            stopifnot(0==(wthr_matches$Match_String[!(wthr_matches$Match_String %in% rownames(K.weather))] %>% unique()))\n",
    "\n",
    "            K.weather <- K.weather[wthr_matches$Match_String, wthr_matches$Match_String]\n",
    "\n",
    "            saveRDS(K.weather , file = matrix_file_path)\n",
    "\n",
    "            rm(list = c('Wdat', 'K.weather'))\n",
    "            gc()   \n",
    "        }\n",
    "    }\n",
    "\n",
    "    matrix_file <- paste0(\"phno_ref\", \"_\", as.character(CV), \"_\", save_suffix, '.csv')        \n",
    "    matrix_file_path = paste0(\"./data/Processed/\", matrix_file)\n",
    "    write.csv(phno, matrix_file_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6cca6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-23T02:13:17.375942Z",
     "start_time": "2022-12-23T02:13:17.317Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "595.6px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
