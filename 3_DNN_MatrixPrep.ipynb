{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn import preprocessing # LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error # if squared=False; RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f316cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('./data/Processed/meta0.csv')\n",
    "# meta['Date_Planted'] = meta['Date_Planted'].astype(int)\n",
    "# meta['Date_Harvested'] = meta['Date_Harvested'].astype(int)\n",
    "phno = pd.read_csv('./data/Processed/phno0.csv')\n",
    "soil = pd.read_csv('./data/Processed/soil0.csv')\n",
    "wthr = pd.read_csv('./data/Processed/wthr0.csv')\n",
    "# wthrWide = pd.read_csv('./data/Processed/wthrWide0.csv')\n",
    "cgmv = pd.read_csv('./data/Processed/cgmv0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((phno.Yield_Mg_ha.notna()) | (phno.Year == 2022))\n",
    "phno = phno.loc[mask, :].reset_index().drop(columns = 'index')\n",
    "phno = phno.loc[:, ['Env', 'Year', 'Hybrid', 'Yield_Mg_ha']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec008a",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5b519",
   "metadata": {},
   "source": [
    "## Prep CVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f443f0",
   "metadata": {},
   "source": [
    "## Prep y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920cca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "YMat = np.array(phno.Yield_Mg_ha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99012086",
   "metadata": {},
   "source": [
    "## One Hot Encode G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = phno.loc[:, ['Env', 'Year', 'Hybrid', 'Yield_Mg_ha']]\n",
    "temp = pd.concat([temp, temp.Hybrid.str.split('/', expand=True)], axis=1\n",
    "        ).rename(columns = {0:'P0', 1:'P1'})\n",
    "temp\n",
    "uniq_parents = list(set(pd.concat([temp['P0'], temp['P1']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5252b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GMat = np.zeros([temp.shape[0], len(uniq_parents)])\n",
    "\n",
    "# for each uniq_parent \n",
    "for j in range(len(uniq_parents)):\n",
    "    for parent in ['P0', 'P1']:\n",
    "        mask = (temp[parent] == uniq_parents[j]) \n",
    "        GMat[temp.loc[mask, ].index, j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97622023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm there are two parents encoded for each observation\n",
    "assert 2 == np.min(np.sum(GMat, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd878c",
   "metadata": {},
   "source": [
    "## Make S Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMat = phno.loc[:, ['Env']].merge(soil.drop(columns = ['Unnamed: 0', 'Year'])).drop(columns = ['Env'])\n",
    "SMatNames = list(SMat)\n",
    "SMat = np.array(SMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168fe87",
   "metadata": {},
   "source": [
    "## Prep W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dae4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: (N,Cin,Lin)(N,Cin,Lin) or (Cin,Lin)(Cin,Lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b738b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WMatNames = list(wthr.drop(columns = ['Unnamed: 0', 'Env', 'Year', 'Date', 'DOY']))\n",
    "WMat = np.zeros([   # Pytorch uses\n",
    "    phno.shape[0],  # N\n",
    "    len(WMatNames), # Cin\n",
    "    np.max(wthr.DOY)# Lin\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa41a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138263/138263 [00:04<00:00, 31512.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all obs, but only add each env once (add to all relevant obs)\n",
    "added_envs = []\n",
    "for i in tqdm.tqdm(phno.index):\n",
    "    env = phno.loc[i, 'Env']\n",
    "\n",
    "    if env in added_envs:\n",
    "        pass\n",
    "    else:\n",
    "        mask = (phno.Env == env)\n",
    "        WMat_idxs = phno.loc[mask, ].index\n",
    "\n",
    "        # selected data is transposed to match correct shape\n",
    "        wthr_mask = (wthr.Env == env)\n",
    "        WMat[WMat_idxs, :, :] = wthr.loc[wthr_mask, \n",
    "                                   ].sort_values('DOY'\n",
    "                                   ).drop(columns = ['Unnamed: 0', 'Env', \n",
    "                                                     'Year', 'Date', 'DOY']).T\n",
    "\n",
    "        added_envs += [env]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f0094",
   "metadata": {},
   "source": [
    "## Prep CGMV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430668e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMatNames = list(cgmv.drop(columns = ['Unnamed: 0', 'Env', 'Year']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMat = np.zeros([   \n",
    "    phno.shape[0],  \n",
    "    len(MMatNames)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7273cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 138263/138263 [00:02<00:00, 56305.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop through all obs, but only add each env once (add to all relevant obs)\n",
    "added_envs = []\n",
    "for i in tqdm.tqdm(phno.index):\n",
    "    env = phno.loc[i, 'Env']\n",
    "\n",
    "    if env in added_envs:\n",
    "        pass\n",
    "    else:\n",
    "        mask = (phno.Env == env)\n",
    "        MMat_idxs = phno.loc[mask, ].index\n",
    "\n",
    "        # selected data is transposed to match correct shape\n",
    "        cgmv_mask = (cgmv.Env == env)\n",
    "        MMat[MMat_idxs, :] = cgmv.loc[cgmv_mask, \n",
    "                                ].drop(columns = ['Unnamed: 0', 'Env', 'Year'])\n",
    "\n",
    "        added_envs += [env]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3405c8",
   "metadata": {},
   "source": [
    "# Save data\n",
    "This will streamline model generation. I'll just need to load these files in and can directly begin modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c38be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './data/Processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7defc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True == False:\n",
    "    np.save(save_path+'GMatNames.npy', uniq_parents)\n",
    "    np.save(save_path+'SMatNames.npy', SMatNames)\n",
    "    np.save(save_path+'WMatNames.npy', WMatNames)\n",
    "    np.save(save_path+'MMatNames.npy', MMatNames)\n",
    "\n",
    "    phno.to_csv(save_path+'phno3.csv', index=False)\n",
    "\n",
    "    np.save(save_path+'YMat3.npy', YMat)\n",
    "    np.save(save_path+'GMat3.npy', GMat)\n",
    "    np.save(save_path+'SMat3.npy', SMat)\n",
    "    np.save(save_path+'WMat3.npy', WMat)\n",
    "    np.save(save_path+'MMat3.npy', MMat)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
